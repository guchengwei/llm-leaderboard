#!/bin/bash
# quick_setup.sh - LLM環境の簡単セットアップスクリプト

set -e

echo "=== LLM Stack セットアップ ==="
echo ""

# GPU数の検出
detect_gpus() {
    if command -v nvidia-smi &> /dev/null; then
        local gpu_count=$(nvidia-smi --list-gpus | wc -l)
        echo $gpu_count
    else
        echo "0"
    fi
}

GPU_COUNT=$(detect_gpus)

echo "検出されたGPU数: $GPU_COUNT"
echo ""

if [ "$GPU_COUNT" -eq 0 ]; then
    echo "エラー: GPUが検出されませんでした。"
    echo "NVIDIA ドライバーとDocker NVIDIAランタイムがインストールされていることを確認してください。"
    exit 1
fi

# 設定の選択
echo "GPU構成を選択してください:"
echo "1) 2GPU環境 (vLLM: GPU 0, Leaderboard: GPU 1)"
echo "2) 4GPU環境 (vLLM: GPU 0-1, Leaderboard: GPU 2-3)"
echo "3) 8GPU環境 (vLLM: GPU 0-3, Leaderboard: GPU 4-7)"
echo "4) カスタム設定"
echo "5) 最小構成"

read -p "選択 (1-5): " choice

case $choice in
    1)
        if [ "$GPU_COUNT" -lt 2 ]; then
            echo "エラー: 2GPU構成には最低2つのGPUが必要です。"
            exit 1
        fi
        VLLM_GPUS="0"
        LEADERBOARD_GPUS="1"
        TENSOR_PARALLEL_SIZE=1
        ;;
    2)
        if [ "$GPU_COUNT" -lt 4 ]; then
            echo "エラー: 4GPU構成には最低4つのGPUが必要です。"
            exit 1
        fi
        VLLM_GPUS="0,1"
        LEADERBOARD_GPUS="2,3"
        TENSOR_PARALLEL_SIZE=2
        ;;
    3)
        if [ "$GPU_COUNT" -lt 8 ]; then
            echo "エラー: 8GPU構成には最低8つのGPUが必要です。"
            exit 1
        fi
        VLLM_GPUS="0,1,2,3"
        LEADERBOARD_GPUS="4,5,6,7"
        TENSOR_PARALLEL_SIZE=4
        ;;
    4)
        read -p "vLLM用GPU (カンマ区切り, 例: 0,1): " VLLM_GPUS
        read -p "Leaderboard用GPU (カンマ区切り, 例: 2,3): " LEADERBOARD_GPUS
        IFS=',' read -ra VLLM_ARRAY <<< "$VLLM_GPUS"
        TENSOR_PARALLEL_SIZE=${#VLLM_ARRAY[@]}
        ;;
    5)
        VLLM_GPUS="0"
        LEADERBOARD_GPUS=""
        TENSOR_PARALLEL_SIZE=1
        ;;
    *)
        echo "無効な選択です。"
        exit 1
        ;;
esac

# モデル名の必須入力
echo ""
echo "=== モデル設定 ==="
echo "例: SakanaAI/TinySwallow-1.5B-Instruct, microsoft/DialoGPT-medium, gpt2"
echo ""

# モデル名の必須入力
while true; do
    read -p "モデル名を入力してください: " MODEL_NAME
    if [ -n "$MODEL_NAME" ]; then
        break
    else
        echo "エラー: モデル名は必須です。再度入力してください。"
    fi
done

# 最大トークン長の入力
read -p "最大トークン長 [デフォルト: 4096]: " MAX_MODEL_LEN
MAX_MODEL_LEN=${MAX_MODEL_LEN:-4096}

# 入力確認
echo ""
echo "=== 入力確認 ==="
echo "選択されたモデル: $MODEL_NAME"
echo "最大トークン長: $MAX_MODEL_LEN"
echo ""
read -p "この設定で続行しますか？ (y/N): " confirm

if [[ ! "$confirm" =~ ^[Yy]$ ]]; then
    echo "セットアップを中止しました。"
    exit 0
fi

# 個別GPU環境変数を生成
generate_gpu_vars() {
    local gpu_list="$1"
    local prefix="$2"
    local vars=""
    
    if [ -z "$gpu_list" ]; then
        echo "${prefix}_GPU_COUNT=0"
        return
    fi
    
    IFS=',' read -ra GPU_ARRAY <<< "$gpu_list"
    for i in "${!GPU_ARRAY[@]}"; do
        vars+="${prefix}_GPU_${i}=${GPU_ARRAY[i]}"$'\n'
    done
    vars+="${prefix}_GPU_COUNT=${#GPU_ARRAY[@]}"
    echo "$vars"
}

# GPU設定を配列形式に変換
convert_to_array() {
    local gpu_list="$1"
    if [ -z "$gpu_list" ]; then
        echo "[]"
        return
    fi
    IFS=',' read -ra GPU_ARRAY <<< "$gpu_list"
    local result="["
    for i in "${!GPU_ARRAY[@]}"; do
        result+="\"${GPU_ARRAY[i]}\""
        if [[ $i -lt $((${#GPU_ARRAY[@]} - 1)) ]]; then
            result+=","
        fi
    done
    result+="]"
    echo "$result"
}

VLLM_GPU_VARS=$(generate_gpu_vars "$VLLM_GPUS" "VLLM")
LEADERBOARD_GPU_VARS=$(generate_gpu_vars "$LEADERBOARD_GPUS" "LEADERBOARD")
VLLM_GPU_IDS=$(convert_to_array "$VLLM_GPUS")
LEADERBOARD_GPU_IDS=$(convert_to_array "$LEADERBOARD_GPUS")

# env_filesディレクトリの作成
echo ""
echo "環境設定ファイルを作成中..."

mkdir -p ./env_files

# モデル名からファイル名を生成（スラッシュを置換、タイムスタンプ追加でユニーク化）
MODEL_FILE_NAME=$(echo "$MODEL_NAME" | sed 's/\//_/g' | sed 's/[^a-zA-Z0-9_-]/_/g')
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
ENV_FILENAME="${MODEL_FILE_NAME}_${TIMESTAMP}.env"
ENV_FILEPATH="./env_files/${ENV_FILENAME}"

echo "設定ファイル: $ENV_FILEPATH"

cat > "$ENV_FILEPATH" << EOL
# LLM Stack Configuration
# Generated by quick_setup.sh

# Model Settings
MODEL_NAME=$MODEL_NAME
SERVED_MODEL_NAME=$MODEL_NAME
DTYPE=half
MAX_MODEL_LEN=$MAX_MODEL_LEN
VLLM_PORT=8000

# GPU Configuration - Array Format (for compatibility)
VLLM_GPU_IDS=$VLLM_GPU_IDS
TENSOR_PARALLEL_SIZE=$TENSOR_PARALLEL_SIZE
LEADERBOARD_GPU_IDS=$LEADERBOARD_GPU_IDS
NVIDIA_VISIBLE_DEVICES=all

# GPU Configuration - Individual GPU IDs
$VLLM_GPU_VARS
$LEADERBOARD_GPU_VARS

# Required API Keys
WANDB_API_KEY=
OPENAI_API_KEY=

# Other API Keys (optional - set as needed)
HUGGINGFACE_HUB_TOKEN=
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=
COHERE_API_KEY=
MISTRAL_API_KEY=
UPSTAGE_API_KEY=

# AWS Configuration (optional)
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_DEFAULT_REGION=us-east-1

# Azure OpenAI (optional)
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
OPENAI_API_TYPE=

# Other Settings
LANG=ja_JP.UTF-8
PYTHONPATH=/workspace
JUMANPP_COMMAND=/usr/local/bin/jumanpp
EOL

echo "設定完了！"
echo ""
echo "=== 設定サマリー ==="
echo "モデル: $MODEL_NAME"
echo "最大トークン長: $MAX_MODEL_LEN"
echo "vLLM GPU: $VLLM_GPU_IDS (Tensor Parallel: $TENSOR_PARALLEL_SIZE)"
if [ -n "$LEADERBOARD_GPUS" ]; then
    echo "Leaderboard GPU: $LEADERBOARD_GPU_IDS"
else
    echo "Leaderboard: CPU実行"
fi
echo "設定ファイル: $ENV_FILEPATH"
echo "==================="
echo ""

# .envファイルへのコピー
echo "次のステップ:"
echo "1. 必要に応じて他のAPI keyを設定してください"
echo "2. 設定ファイルを.envにコピー:"
echo "   cp \"$ENV_FILEPATH\" .env"
echo "3. generate_docker_override.shを実行"