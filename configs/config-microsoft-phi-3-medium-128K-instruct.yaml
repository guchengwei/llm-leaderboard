wandb:
  run_name: "microsoft/phi-3-medium-128k-instruct"
api: vllm-docker
base_url: http://vllm:8000/v1
batch_size: 32
model:
  use_wandb_artifacts: false
  pretrained_model_name_or_path: microsoft/phi-3-medium-128k-instruct #if you use openai api, put the name of model
  bfcl_model_id: united_oss_fc
  size_category: Small (<10B)
  size: 3821079552
  release_date: 6/27/2024

generator:
  extra_body:
    chat_template_kwargs:
        enable_thinking: false
  max_tokens: 31232
  temperature: 0.1
  top_p: 1

vllm:
    device_map: null
    disable_triton_mma: false
    dtype: null
    gpu_memory_utilization: 0.8
    lifecycle: always_on
    max_model_len: 31232
    #reasoning_parser: 
    enable_auto_tool_choice: true
    tool_call_parser: phi4_mini_json
    trust_remote_code: true
    vllm_tag: v0.8.5

# Number of GPUs for tensor parallelism
num_gpus: 1 
