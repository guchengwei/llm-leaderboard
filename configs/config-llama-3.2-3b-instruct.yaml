wandb:
  run_name: "meta-llama/Llama-3.2-3B-Instruct" # use run_name defined above

api: vllm-docker
num_gpus: 2
batch_size: 256 # vllmは256, apiは32を推奨

model:
  use_wandb_artifacts: false
  pretrained_model_name_or_path: "meta-llama/Llama-3.2-3B-Instruct" #if you use openai api, put the name of model
  bfcl_model_id: "meta-llama/Llama-3.2-3B-Instruct-FC"
  size_category: "Small (<10B)"
  size: 3212749824
  release_date: "9/25/2024"

vllm:
  vllm_tag: v0.10.1
