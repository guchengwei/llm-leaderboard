wandb:
  run_name: openai/o3-2025-04-16
api: openai_responses # openai, anthropic, google,..
batch_size: 32
model:
  pretrained_model_name_or_path: o3-2025-04-16 #if you use openai api, put the name of model
  bfcl_model_id: "o3-2025-04-16-FC" # find id from "llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/SUPPORTED_MODELS.md"
  base_model: "unknown"
  size_category: api
  size: null
  release_date: 4/16/2025 # format: MM/DD/YYYY

generator:
  # temperature は外す（o3 は非対応）
  max_output_tokens: 800000  
  reasoning:
    effort: "high"          # "low" | "medium" | "high"
    summary: "auto"        
  include:
    - "reasoning.encrypted_content"
  parallel_tool_calls: true