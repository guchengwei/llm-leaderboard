
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m Launch agent received job:
[34m[1mwandb[39m[22m: {'runQueueItemId': 'UnVuUXVldWVJdGVtOjM3NjQ2NDExMA==',
[34m[1mwandb[39m[22m:  'runSpec': {'_wandb_job_collection_id': 'QXJ0aWZhY3RDb2xsZWN0aW9uOjc5NDQ3NjMx',
[34m[1mwandb[39m[22m:              'author': 'keisuke-kamata',
[34m[1mwandb[39m[22m:              'entity': 'wandb',
[34m[1mwandb[39m[22m:              'job': 'wandb/LLM_evaluation_Japan_public/job-source-LLM_evaluation_Japan_public-japanese-task-evaluation.py:latest',
[34m[1mwandb[39m[22m:              'overrides': {'args': ['--wandb_project',
[34m[1mwandb[39m[22m:                                     'LLM_evaluation_Japan_public',
[34m[1mwandb[39m[22m:                                     '--wandb_entity',
[34m[1mwandb[39m[22m:                                     'wandb',
[34m[1mwandb[39m[22m:                                     '--model_name',
[34m[1mwandb[39m[22m:                                     'cyberagent/open-calm-small',
[34m[1mwandb[39m[22m:                                     '--prompt_type',
[34m[1mwandb[39m[22m:                                     'others'],
[34m[1mwandb[39m[22m:                            'entry_point': [],
[34m[1mwandb[39m[22m:                            'run_config': {'model_name': 'rinna/japanese-gpt-neox-3.6b-instruction-ppo',
[34m[1mwandb[39m[22m:                                           'prompt_type': 'rinna',
[34m[1mwandb[39m[22m:                                           'wandb_entity': 'wandb',
[34m[1mwandb[39m[22m:                                           'wandb_project': 'jap-llm-eval-test'}},
[34m[1mwandb[39m[22m:              'project': 'jap-llm-eval-test',
[34m[1mwandb[39m[22m:              'resource': 'local-container',
[34m[1mwandb[39m[22m:              'resource_args': {'local-container': {'env': 'LANG=ja_JP.UTF-8',
[34m[1mwandb[39m[22m:                                                    'gpus': 'all',
[34m[1mwandb[39m[22m:                                                    'volume': ['./src:/app']}}}}
[34m[1mwandb[39m[22m:
[34m[1mwandb[39m[22m: [35mlaunch:[39m Launching job: wandb/LLM_evaluation_Japan_public/job-source-LLM_evaluation_Japan_public-japanese-task-evaluation.py:latest
[34m[1mwandb[39m[22m:   2 of 2 files downloaded.
[34m[1mwandb[39m[22m:   3 of 3 files downloaded.
#1 [internal] load .dockerignore
#1 transferring context: 2B done
#1 DONE 0.1s
#2 [internal] load build definition from Dockerfile.wandb-autogenerated
#2 transferring dockerfile: 1.25kB done
#2 DONE 0.1s
#3 [internal] load metadata for docker.io/library/python:3.10
#3 ...
#4 [auth] library/python:pull token for registry-1.docker.io
#4 DONE 0.0s
#5 [internal] load metadata for docker.io/library/python:3.10-buster
#5 DONE 2.0s
#3 [internal] load metadata for docker.io/library/python:3.10
#3 DONE 2.0s
#6 [internal] settings cache mount permissions
#6 DONE 0.0s
#7 [build 1/4] FROM docker.io/library/python:3.10@sha256:a8462db480ec3a74499a297b1f8e074944283407b7a417f22f20d8e2e1619782
#7 DONE 0.0s
#8 [base 1/8] FROM docker.io/library/python:3.10-buster@sha256:31a8498af27dba1f431f2df60189ca79ff5f440cfa7b6dea2da6ab15c74abcd4
#8 DONE 0.0s
#9 [internal] load build context
#9 transferring context: 40.98kB done
#9 DONE 0.0s
#10 [base 2/8] COPY --from=build /env /env
#10 CACHED
#11 [build 2/4] RUN python -m venv /env
#11 CACHED
#12 [base 3/8] RUN useradd     --create-home     --no-log-init     --shell /bin/bash     --gid 0     --uid 1000     olachinkeigpu || echo ""
#12 CACHED
#13 [build 4/4] RUN --mount=type=cache,mode=0777,target=/root/.cache/pip python _wandb_bootstrap.py
#13 CACHED
#14 [base 4/8] WORKDIR /home/olachinkeigpu
#14 CACHED
#15 [build 3/4] COPY src/requirements.frozen.txt _wandb_bootstrap.py ./
#15 CACHED
#16 [base 5/8] RUN chown -R 1000 /home/olachinkeigpu
#16 CACHED
#17 [base 6/8] RUN mkdir -p /home/olachinkeigpu/.cache && chown -R 1000 /home/olachinkeigpu/.cache
#17 CACHED
#18 [base 7/8] COPY --chown=1000 src/ /home/olachinkeigpu
#18 DONE 0.0s
#19 [base 8/8] COPY ./src/_wandb_default_entrypoint /home/olachinkeigpu
#19 DONE 0.1s
#20 exporting to image
#20 exporting layers 0.1s done
#20 writing image sha256:5ba05582618469f610eb42e42cfda5aac58feb8b9fe379f1843d3392a56808f2 done
#20 naming to docker.io/library/wandb__llm_evaluation_japan_public__job-source-llm_evaluation_japan_public-japanese-task-evaluation.py:eb4fd358 done
#20 DONE 0.1s
#1 [internal] load .dockerignore
#1 transferring context: 2B done
#1 DONE 0.1s
#2 [internal] load build definition from Dockerfile.wandb-autogenerated
#2 transferring dockerfile: 1.25kB done
#2 DONE 0.1s
#3 [internal] load metadata for docker.io/library/python:3.10
#3 ...
#4 [auth] library/python:pull token for registry-1.docker.io
#4 DONE 0.0s
#5 [internal] load metadata for docker.io/library/python:3.10-buster
#5 DONE 2.0s
#3 [internal] load metadata for docker.io/library/python:3.10
#3 DONE 2.0s
#6 [internal] settings cache mount permissions
#6 DONE 0.0s
#7 [build 1/4] FROM docker.io/library/python:3.10@sha256:a8462db480ec3a74499a297b1f8e074944283407b7a417f22f20d8e2e1619782
#7 DONE 0.0s
#8 [base 1/8] FROM docker.io/library/python:3.10-buster@sha256:31a8498af27dba1f431f2df60189ca79ff5f440cfa7b6dea2da6ab15c74abcd4
#8 DONE 0.0s
#9 [internal] load build context
#9 transferring context: 40.98kB done
#9 DONE 0.0s
#10 [base 2/8] COPY --from=build /env /env
#10 CACHED
#11 [build 2/4] RUN python -m venv /env
#11 CACHED
#12 [base 3/8] RUN useradd     --create-home     --no-log-init     --shell /bin/bash     --gid 0     --uid 1000     olachinkeigpu || echo ""
#12 CACHED
#13 [build 4/4] RUN --mount=type=cache,mode=0777,target=/root/.cache/pip python _wandb_bootstrap.py
#13 CACHED
#14 [base 4/8] WORKDIR /home/olachinkeigpu
#14 CACHED
#15 [build 3/4] COPY src/requirements.frozen.txt _wandb_bootstrap.py ./
#15 CACHED
#16 [base 5/8] RUN chown -R 1000 /home/olachinkeigpu
#16 CACHED
#17 [base 6/8] RUN mkdir -p /home/olachinkeigpu/.cache && chown -R 1000 /home/olachinkeigpu/.cache
#17 CACHED
#18 [base 7/8] COPY --chown=1000 src/ /home/olachinkeigpu
#18 DONE 0.0s
#19 [base 8/8] COPY ./src/_wandb_default_entrypoint /home/olachinkeigpu
#19 DONE 0.1s
#20 exporting to image
#20 exporting layers 0.1s done
#20 writing image sha256:5ba05582618469f610eb42e42cfda5aac58feb8b9fe379f1843d3392a56808f2 done
#20 naming to docker.io/library/wandb__llm_evaluation_japan_public__job-source-llm_evaluation_japan_public-japanese-task-evaluation.py:eb4fd358 done
#20 DONE 0.1s
[34m[1mwandb[39m[22m: [35mlaunch:[39m Launching run in docker with command: docker run --rm -e WANDB_BASE_URL=https://api.wandb.ai -e WANDB_API_KEY -e WANDB_PROJECT=jap-llm-eval-test -e WANDB_ENTITY=wandb -e WANDB_LAUNCH=True -e WANDB_RUN_ID=hzik6u44 -e WANDB_USERNAME=keisuke-kamata -e WANDB_CONFIG='{"model_name": "rinna/japanese-gpt-neox-3.6b-instruction-ppo", "prompt_type": "rinna", "wandb_entity": "wandb", "wandb_project": "jap-llm-eval-test"}' -e WANDB_ARTIFACTS='{"_wandb_job": "wandb/LLM_evaluation_Japan_public/job-source-LLM_evaluation_Japan_public-japanese-task-evaluation.py:latest"}' -e WANDB_ARGS='--wandb_project LLM_evaluation_Japan_public --wandb_entity wandb --model_name cyberagent/open-calm-small --prompt_type others' --env LANG=ja_JP.UTF-8 --gpus all --volume ./src:/app wandb__llm_evaluation_japan_public__job-source-llm_evaluation_japan_public-japanese-task-evaluation.py:eb4fd358
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 running 1 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m Job finished with ID: 3758379
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m Launch agent received job:
[34m[1mwandb[39m[22m: {'runQueueItemId': 'UnVuUXVldWVJdGVtOjM3NjQ2NDE1Mg==',
[34m[1mwandb[39m[22m:  'runSpec': {'_wandb_job_collection_id': 'QXJ0aWZhY3RDb2xsZWN0aW9uOjc5NDQ3NjMx',
[34m[1mwandb[39m[22m:              'author': 'keisuke-kamata',
[34m[1mwandb[39m[22m:              'entity': 'wandb',
[34m[1mwandb[39m[22m:              'job': 'wandb/LLM_evaluation_Japan_public/job-source-LLM_evaluation_Japan_public-japanese-task-evaluation.py:latest',
[34m[1mwandb[39m[22m:              'overrides': {'args': ['--wandb_project',
[34m[1mwandb[39m[22m:                                     'LLM_evaluation_Japan_public',
[34m[1mwandb[39m[22m:                                     '--wandb_entity',
[34m[1mwandb[39m[22m:                                     'wandb',
[34m[1mwandb[39m[22m:                                     '--model_name',
[34m[1mwandb[39m[22m:                                     'cyberagent/open-calm-small',
[34m[1mwandb[39m[22m:                                     '--prompt_type',
[34m[1mwandb[39m[22m:                                     'others'],
[34m[1mwandb[39m[22m:                            'entry_point': [],
[34m[1mwandb[39m[22m:                            'run_config': {'model_name': 'cyberagent/open-calm-middle',
[34m[1mwandb[39m[22m:                                           'prompt_type': 'others',
[34m[1mwandb[39m[22m:                                           'wandb_entity': 'wandb',
[34m[1mwandb[39m[22m:                                           'wandb_project': 'jap-llm-eval-test'}},
[34m[1mwandb[39m[22m:              'project': 'jap-llm-eval-test',
[34m[1mwandb[39m[22m:              'resource': 'local-container',
[34m[1mwandb[39m[22m:              'resource_args': {'local-container': {'env': 'LANG=ja_JP.UTF-8',
[34m[1mwandb[39m[22m:                                                    'gpus': 'all',
[34m[1mwandb[39m[22m:                                                    'volume': ['./src:/app']}}}}
[34m[1mwandb[39m[22m:
[34m[1mwandb[39m[22m: [35mlaunch:[39m Launching job: wandb/LLM_evaluation_Japan_public/job-source-LLM_evaluation_Japan_public-japanese-task-evaluation.py:latest
[34m[1mwandb[39m[22m:   2 of 2 files downloaded.
[34m[1mwandb[39m[22m:   3 of 3 files downloaded.
[34m[1mwandb[39m[22m: [35mlaunch:[39m Launching run in docker with command: docker run --rm -e WANDB_BASE_URL=https://api.wandb.ai -e WANDB_API_KEY -e WANDB_PROJECT=jap-llm-eval-test -e WANDB_ENTITY=wandb -e WANDB_LAUNCH=True -e WANDB_RUN_ID=9122dur9 -e WANDB_USERNAME=keisuke-kamata -e WANDB_CONFIG='{"model_name": "cyberagent/open-calm-middle", "prompt_type": "others", "wandb_entity": "wandb", "wandb_project": "jap-llm-eval-test"}' -e WANDB_ARTIFACTS='{"_wandb_job": "wandb/LLM_evaluation_Japan_public/job-source-LLM_evaluation_Japan_public-japanese-task-evaluation.py:latest"}' -e WANDB_ARGS='--wandb_project LLM_evaluation_Japan_public --wandb_entity wandb --model_name cyberagent/open-calm-small --prompt_type others' --env LANG=ja_JP.UTF-8 --gpus all --volume ./src:/app wandb__llm_evaluation_japan_public__job-source-llm_evaluation_japan_public-japanese-task-evaluation.py:eb4fd358
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 running 1 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m Job finished with ID: 3758828
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 polling on queues llm-jap-evaluation-kei-gpu, running 0 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m Launch agent received job:
[34m[1mwandb[39m[22m: {'runQueueItemId': 'UnVuUXVldWVJdGVtOjM3NjQ2NDIwNA==',
[34m[1mwandb[39m[22m:  'runSpec': {'_wandb_job_collection_id': 'QXJ0aWZhY3RDb2xsZWN0aW9uOjc5NDQ3NjMx',
[34m[1mwandb[39m[22m:              'author': 'keisuke-kamata',
[34m[1mwandb[39m[22m:              'entity': 'wandb',
[34m[1mwandb[39m[22m:              'job': 'wandb/LLM_evaluation_Japan_public/job-source-LLM_evaluation_Japan_public-japanese-task-evaluation.py:latest',
[34m[1mwandb[39m[22m:              'overrides': {'args': ['--wandb_project',
[34m[1mwandb[39m[22m:                                     'LLM_evaluation_Japan_public',
[34m[1mwandb[39m[22m:                                     '--wandb_entity',
[34m[1mwandb[39m[22m:                                     'wandb',
[34m[1mwandb[39m[22m:                                     '--model_name',
[34m[1mwandb[39m[22m:                                     'cyberagent/open-calm-small',
[34m[1mwandb[39m[22m:                                     '--prompt_type',
[34m[1mwandb[39m[22m:                                     'others'],
[34m[1mwandb[39m[22m:                            'entry_point': [],
[34m[1mwandb[39m[22m:                            'run_config': {'model_name': 'cyberagent/open-calm-medium',
[34m[1mwandb[39m[22m:                                           'prompt_type': 'others',
[34m[1mwandb[39m[22m:                                           'wandb_entity': 'wandb',
[34m[1mwandb[39m[22m:                                           'wandb_project': 'jap-llm-eval-test'}},
[34m[1mwandb[39m[22m:              'project': 'jap-llm-eval-test',
[34m[1mwandb[39m[22m:              'resource': 'local-container',
[34m[1mwandb[39m[22m:              'resource_args': {'local-container': {'env': 'LANG=ja_JP.UTF-8',
[34m[1mwandb[39m[22m:                                                    'gpus': 'all',
[34m[1mwandb[39m[22m:                                                    'volume': ['./src:/app']}}}}
[34m[1mwandb[39m[22m:
[34m[1mwandb[39m[22m: [35mlaunch:[39m Launching job: wandb/LLM_evaluation_Japan_public/job-source-LLM_evaluation_Japan_public-japanese-task-evaluation.py:latest
[34m[1mwandb[39m[22m:   2 of 2 files downloaded.
[34m[1mwandb[39m[22m:   3 of 3 files downloaded.
[34m[1mwandb[39m[22m: [35mlaunch:[39m Launching run in docker with command: docker run --rm -e WANDB_BASE_URL=https://api.wandb.ai -e WANDB_API_KEY -e WANDB_PROJECT=jap-llm-eval-test -e WANDB_ENTITY=wandb -e WANDB_LAUNCH=True -e WANDB_RUN_ID=8ut9i4ix -e WANDB_USERNAME=keisuke-kamata -e WANDB_CONFIG='{"model_name": "cyberagent/open-calm-medium", "prompt_type": "others", "wandb_entity": "wandb", "wandb_project": "jap-llm-eval-test"}' -e WANDB_ARTIFACTS='{"_wandb_job": "wandb/LLM_evaluation_Japan_public/job-source-LLM_evaluation_Japan_public-japanese-task-evaluation.py:latest"}' -e WANDB_ARGS='--wandb_project LLM_evaluation_Japan_public --wandb_entity wandb --model_name cyberagent/open-calm-small --prompt_type others' --env LANG=ja_JP.UTF-8 --gpus all --volume ./src:/app wandb__llm_evaluation_japan_public__job-source-llm_evaluation_japan_public-japanese-task-evaluation.py:eb4fd358
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 running 1 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 running 1 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 running 1 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 running 1 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 running 1 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 running 1 out of a maximum of 1 jobs
[34m[1mwandb[39m[22m: [35mlaunch:[39m Shutting down, active jobs:
[34m[1mwandb[39m[22m: [35mlaunch:[39m agent cu7kbjn5 running 1 out of a maximum of 1 jobs